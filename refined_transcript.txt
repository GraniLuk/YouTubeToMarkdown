
# AI-Assisted Coding and Prompt Engineering: A Detailed Breakdown

## Part 1: AI Coding Demos

### Introduction (0:02-0:32)
The speaker is addressing fixing the code, mentioning they're nearing completion and will run the program without pauses in a subsequent video. The code is now building and running.

### Tic-Tac-Toe Demo (0:32-1:03)
The speaker identifies the running application as a Tic-Tac-Toe program. They attempted to play against the AI but lost, noting that the AI-created program lacks AI functionality. It simply allows two players to play against each other on the same board. The key point is that it compiled successfully without requiring any modifications by the user.

### Cost Analysis and Next Steps (1:03-1:22)
The process cost only 37 cents. The next step involves creating a module for calculations.

### Project Structure and Iterative Development (1:22-1:43)
The file creation process is complete and follows an iterative approach. The .NET executable was utilized to create the initial project structure. Subsequently, files were populated and corrected.

### Auto-Approval and Learning (1:46-2:27)
The speaker discusses the possibility of pausing the process for explanations, noting it might not be directly possible. However, without auto-approval enabled, users can follow each step, ask questions, and potentially change their approach. Auto-approval streamlines the process of reading and editing files. This manual approach is also beneficial for learning, allowing users to understand the "how" behind the game's creation, rather than just playing the finished product.

### GigaPilot Client and LLM Model Flexibility (2:35-3:06)
The speaker admits a lack of expertise on GitHub Copilot, suggesting users can click for more information. The tool allows injecting any Large Language Model (LLM) desired. Originally designed for the Claude model, it now supports various LLMs, including local ones.

### Cursor Comparison and Tool Appreciation (3:06-3:23)
The speaker had initially believed the tool was exclusively cloud-integrated but acknowledges its compatibility with any model, including Cursor. It's mentioned that the client is seen as a competitor to Cursor. The speaker expresses admiration for the tool's development, especially considering it was built without explicit guidance.

### WinForms and Explanations (3:23-3:41)
The use of WinForms was nicely described, and everything was well-explained, making it user-friendly.

### Second Demo and Time Constraints (3:41-3:55)
The presenter initially wanted to show a second demo but was unsure of the time. It was determined there wouldn't be time to create the demo using GitHub Copilot, as it would require multiple iterations and more time.

### REST API Demo Introduction (3:55-4:13)
The second demo, titled "Demo One," involves creating a REST API for storing notes in a SQL database. The speaker considers this a more familiar area compared to Tic-Tac-Toe.

### Code Quality Adjustment and Mistake Recognition (4:13-4:42)
The speaker requests a moment to adjust the video quality. Apologizing, the speaker humorously states that "it's not for nerds, we are nerds, so maybe."

### Plan Mode and AI Self-Questioning (4:42-5:06)
The demo is run in plan mode, but the client makes a mistake, asking itself a question instead of the user. This occurred because the speaker selected another question instead of an answer.

### Message Typing and Alternative Suggestions (5:06-5:38)
The client presents a question but requests the user to answer an additional question. Users can type messages directly instead of replying to the suggested answers. The second suggestion is to create a simple REST application to store, retrieve, and delete notes.

### Database Type and Typos (5:38-6:31)
The speaker deviates from the plan and attempts to specify "Postgres SQL" as the database type but introduces a typo. AI is known to work with typos, but in this instance, it doesn't point out the error. It seems the AI is being "nice" by not highlighting the mistake.

### Swagger Endpoint and Code Generation (6:31-6:48)
The speaker requests a Swagger endpoint for testing and documentation. The AI generates example code that will likely be added.

### Time Constraints and Entity Framework (6:48-7:09)
With only six minutes remaining, the speaker expresses uncertainty about having enough time for data access. The AI automatically selects Entity Framework as the technology.

### Command Execution and Cost (7:09-7:39)
It's now time to execute the commands, creating a solution without auto-approval for commands. Auto-approval is only enabled for editing and viewing. Each command requires approval, and the cost for each command is visible.

### Additional Questions and Cost per Command (7:39-8:00)
An additional question appears, and it's clarified that charges apply per command, such as creating a .NET solution project.

### Auto-Approval Clarification (8:00-8:15)
The speaker questions why the system is asking about auto-approval. It's clarified that auto-approval is enabled for written edits but not for commands.

### Architecture and Module Creation (8:15-8:45)
New projects are being created, and it appears to be a clean architecture. The speaker selects "save commands," infrastructure modules, core modules, and the domain module. This suggests a modern architecture.

### Default Architecture and Repository Pattern (8:45-9:15)
The architecture is considered "nice" and is suggested by default, without any specific instructions from the user. Looking at the code reveals the use of the repository pattern.

### Service Layers and Code Quality (9:15-9:30)
The service layers appear to be well-structured, suggesting they were created by a human. This is attributed to the AI's reliance on GitHub repositories.

### Technology Migration and Cost Concerns (9:30-9:43)
The idea of migrating a bank view to a different technology is raised, but cost is a concern.

### Project Completion and GitHub Repository Selection (9:43-10:06)
The project is nearing completion. The biggest challenge lies in choosing the right GitHub repository. The speaker recalls reading about Microsoft's approach to selecting repositories for compilation, noting that they based their selections on star ratings due to the complexity of the task.

### Star-Based Repository Scanning (10:06-10:31)
Repositories are scanned based on their star ratings, with the best ones being prioritized.

### REST API Setup and Connection String (10:31-10:48)
The setup for the REST API "sort program" is almost complete. PostgreSQL and the connection string have been selected.

### Screen Recording Software (10:48-11:06)
The presenter mentions using NVIDIA's screen recording software, "For Nerds."

### Memory Usage and API Execution (11:06-11:23)
The speaker doesn't know if the process uses a lot of memory but believes it shouldn't since it's all for the API. The API shouldn't require significant resources.

### Demo Conclusion and Code Execution (11:26-11:50)
The presenter decides to stop the demo as there is nothing further to show. They explain that the Tic-Tac-Toe game was run using ".NET run" and opened in Visual Studio.

### C# Dev Kit and Enterprise License (11:50-12:17)
The REST API wasn't run in this demo. The speaker mentions using the C# Dev Kit and the possibility of using "your spanks of fun" with an enterprise license, implying it's a paid feature.

### Demo Summary and Feedback (12:17-12:27)
The presenter concludes the two demos and asks for feedback.

### Compilation Errors and Total Cost (12:27-13:05)
The presenter is asked whether the API was compiled and run. It was attempted, but there was a compilation error related to a configuration builder. The total cost for the REST API is unknown.

### Personal Project and Costly Experimentation (13:05-13:20)
The speaker shares that the reason for using the client was for their own project. They intended to showcase it but ended up using the tool for serious development and learning.

### High Costs and Future Demonstration (13:20-13:51)
The speaker admits to spending around $60 on the project without realizing it. They plan to show the project briefly in five minutes and suggest switching to another speaker in the meantime.

### Switching Speakers (13:51-14:00)
The speaker transitions to another presenter, offering to share the "case" as well.

## Part 2: Prompt Engineering

### Introduction to Prompt Engineering (14:00-14:22)
The second speaker begins by confirming screen visibility and introduces the topic of prompt engineering, explaining how to effectively communicate with AI.

### System Prompts Explained (14:22-14:54)
A **system prompt** provides information to the AI (chatbots, etc.) about the desired output. While users often neglect the importance of the initial "Hi, you are a helpful assistant..." prompt, it's crucial.

### AI Iterations and Prompting Improvements (14:54-15:27)
The speaker acknowledges that the information presented might become outdated due to rapid AI advancements. Newer AI iterations are better at understanding user intent, even with poor prompting, but better prompts still make a significant difference.

### Meta Prompts and Multi-Step Processes (15:27-16:22)
The speaker uses a "meta prompt" (a system prompt used to create other system prompts) and finds it highly effective. They credit Madam Wuspoderchuk Overman for sharing this publicly. The meta prompt guides the AI through a series of steps, such as incorporating "few-shot" examples (demonstrating the desired output style). The process is structured into seven steps.

### General Prompt Structure (16:22-17:34)
The general prompt structure is described as somewhat mysterious. The speaker notes the uncertainty around how AI interprets different formatting elements, like capital letters or text enclosed in brackets. Through trial and error, it's been observed that these elements likely influence the AI's response.

### Live Demo and AI Variability (17:34-17:52)
The speaker acknowledges the challenges of live AI demos due to the potential for unpredictable outputs. A pre-prepared example will be presented.

### Poem Example (17:52-18:16)
A system prompt was used to instruct the AI to act as a poet and write a short poem about Microsoft. The speaker finds the generated poem uninspiring.

### Meta Prompt Application (18:16-18:51)
The speaker then uses the prompt engineering meta prompt as a system prompt, instructing the AI to generate a prompt for another AI that will act as a poet. This involves a multi-step process, starting with defining the core purpose and objective (creating an original poem with its own style).

### Open AI Playground vs ChatGPT (19:06-19:51)
The speaker explains the key differences between the **Open AI Playground** and **ChatGPT**:
*   The Playground offers more options and control over the AI model, including choosing the specific model and utilizing system prompts.
*   It facilitates debugging prompts in real-time.
*   ChatGPT is free, while the Playground is a paid service.

### Meta Prompt Functionality (19:51-20:16)
The meta prompt functions similarly to the "plan mode" in the client demonstrated earlier. It can be used independently or embedded within brackets labeled as "system prompt" in platforms like Perplexity or GPT, allowing the AI to recognize its purpose.

### Ongoing Questioning (20:16)
The AI is asking questions about how the speaker thinks and what they want to be.


# AI-Assisted Coding and Prompt Engineering: A Detailed Breakdown (Continued)

## Part 2: Prompt Engineering (Continued)

### Poem Generation and Prompt Refinement (20:16-22:45)

The AI is asking questions about the speaker's preferences regarding the poem's style and content. The AI asks:
*   How the poem should perform.
*   Whether the poem should be funny.
*   If there are any limitations.
*   If there are any topics to avoid.

The AI also explores the possibility of creating examples, which is beneficial when using "few-shot" prompting. Few-shot prompting involves providing the AI with a system prompt and several examples of the desired output to guide its response. When creating prompts, especially system prompts, it's helpful to provide a few examples (3-10 is a good range). For example, if you want the AI to anonymize customer data, you can provide a line of data and specify how the AI should respond with the anonymized version.

The **final prompt** objective is to generate a short, original, humorous poem with a unique style. It aims for humor, allows the AI to decide the format, avoids specific topics unless explicitly requested, and prioritizes humor.

**Example Prompt**:

```
User: Write a poem about cats and AI.
AI: [Response - A humorous poem about cats and AI]
```

### Prompting Based on Previous Interactions (22:45-23:24)

It is inquired whether AI can use the previous prompts to get the feeling of what the user expects. The AI can correlate information from previous prompts and examples. You can extract your prompt history, feed it back to the AI, and ask it to remember the context.

The speaker clarifies that prompts are usually created for specific use cases. However, if you want the AI to maintain a consistent style across different topics, you can attach your prompt history.

### Creating Prompts for AI with AI (23:24-24:03)

The user can leverage AI to create prompts that will then be used to instruct another AI. In this case, the speaker uses a meta prompt to guide the AI in generating a prompt for creating a poem. This generated poem is considered better than the initial poem created without the meta prompt. The speaker appreciated its "banking style" and financial ties.

### Poem Length and Copyright (24:03-24:35)

The poem was intended to be short. Due to potential copyright issues, the poem itself isn't shared directly, but the speaker encourages listeners to try the process themselves.

### Meta Prompt Examples: Insurance Claim Email (24:35-26:37)

The speaker advises listeners to try the meta prompt approach. They share an experience of using it for an insurance claim. They needed to draft an email to an insurance company that was underpaying for an accident claim.

Using the meta prompt, they created a prompt for an AI that acted like a lawyer specializing in recovering money from insurance companies, particularly the specific company in question.

They compared the results of using a simple prompt in Perplexity with the meta prompt approach. The meta prompt resulted in an email with more legalistic paragraphs and relevant references. The simple prompt only provided the average working hour cost in workshops in Poland, referencing random motorcycle workshops. The meta prompt-generated prompt provided data from three motorcycle workshops in Dynes, including prices and descriptions, which ultimately "did the trick."

### Addressing Outdated Knowledge in AI (26:37-28:14)

The speaker shares a challenge: AI models often rely on outdated knowledge. Legal information, for example, changes frequently, rendering AI responses based on older data inaccurate.

The speaker mentions an AI agent specifically trained on Polish law, which is updated frequently. This agent can be used as a reference for other AI models to ensure they have access to the most current legal information.

### AI Ground Search Feature (27:36-28:14)

The speaker experimented with the "ground search" feature, which allows the AI to use Google Search for up-to-date information, but even this didn't completely solve the issue of outdated knowledge. Access to specific legal databases (like "libros") would be more effective.

### Summary and Transition (28:16-28:23)

The speaker concludes their presentation on prompt engineering, offering their experiences and insights.

### Docker Desktop Replacement: Podman Desktop (28:23-32:50)

Another speaker addresses the Docker Desktop license issue, presenting **Podman Desktop** as a free alternative.

When the speaker asked about the license for the Docker Desktop, the answer was no, so they need to use Docker on the WSL system. Because of that, they looked for a similar solution to Docker Desktop that is for free.

*   **Problem**: Needed a containerization solution for development but couldn't get a Docker Desktop license.
*   **Solution**: **Podman Desktop** was presented as a free and lightweight alternative.

**Key Features of Podman Desktop**:

*   Similar interface to Docker Desktop.
*   Manages containers, pods, images, and volumes.
*   Allows access to container logs, summaries, and terminals.
*   Uses `podman compose` commands instead of `docker compose` (e.g., `podman compose down` to stop the environment, `podman compose up` to start it).

**Missing Features (Compared to Docker Desktop)**:

*   Lacks a file navigation tab for browsing container file systems and editing files directly.

**Benefits**:

*   Lightweight.
*   Free for commercial use.

**Installation**: Simple Windows installer.

### Code Example: Podman Compose Commands

```bash
# Stop the entire environment
podman compose down

# Start up the Docker Compose components
podman compose up
```

### Podman Desktop Discussion and Personal Experience (32:50-33:20)

A user shares their positive experience using Podman for a year at Banksoft, highlighting it as a great and reliable replacement for Docker Desktop.

### Introduction to an AI-Powered RAG Solution for Ollama (33:34-34:59)

The speaker introduces a new project created using an AI client plugin, focusing on building a **RAG (Retrieval-Augmented Generation) solution for Ollama**.

**Key Concepts**:

*   **RAG**: A system that enhances large language models (LLMs) by providing them with additional documents or knowledge to improve the accuracy and relevance of their responses.
*   **Ollama**: A tool or platform (in this context) that benefits from the RAG solution.

The project aims to create a repository of documents that Ollama can use to answer prompts. For example, you could feed Ollama a folder containing secret cooking recipes, allowing it to use that knowledge when chatting.

### RAG for Adding Missing Data to LLMs (34:59-36:01)

RAG is particularly useful for adding data that is not already present in the LLM's training data. The speaker's project attempts to add real-time synchronization capabilities. This means that when a new file is added to the monitored folder, it should automatically be synced and available to Ollama within a minute.

### Project Structure and Technology (36:01-36:25)

The project's first version is built using PowerShell for simplicity. The architecture is intentionally simple in this version, with plans for a more sophisticated architecture in the second version.

**Project Components**:

*   PowerShell scripts.
*   REST API proxy: Automatically reads documents and adds them to the prompt.

### Demonstration Setup and File Structure (36:25-37:47)

The speaker sets up a demonstration to showcase the project.

*   A folder named "demo" contains PDF documents.
*   The `setup_rag` script is run, specifying the folder path and file filters. This script installs all necessary requirements automatically.

### Database Technologies Used (37:47-39:10)

*   **Weaviate DB**: A vector database used for storing documents and calculating similarities between them. It's a free and open-source solution.
*   **SQLite**: A database to store information about files and folders. It tracks which files are "dirty" (need processing) and which have already been processed.

### AI-Suggested Architecture (39:10-39:48)

The speaker notes that they specifically requested a simple solution from the AI client. The AI did provide a more sophisticated architecture on a separate branch, which the speaker plans to show later.

### Demonstration Execution and Transparent RAG (39:48-41:39)

The setup process embeds one document into the database. An "AI" folder is created, containing details and a text-based version of the PDF document (because PDFs are converted to text before being added to the vector database).

The speaker then runs the `start` command, which starts the RAG process. A PowerShell script for chatting is also initiated.

The speaker emphasizes the "transparent" nature of the RAG solution. This means that different clients can be used with the RAG system because of the proxy. The proxy automatically adds documents to the prompt, allowing various clients to interact with it.

### Chat Interface and Model Selection (41:39-42:23)

A simple GUI application in PowerShell is used for chatting.

*   The user needs to select a model first (e.g., the "llama" model).
*   A simple "hi" message is sent to initiate the conversation.

### Prompt Vectorization and Similarity Search (42:23-43:40)

The speaker attempts to "hack" the system by asking a question related to the text content of the document. The project converts the prompt into a vector and searches for similar vectors in the Weaviate database. The database contains chunks of text and whole documents. The system responds by indicating that it used context from lines 1 to 23 of the document, along with a similarity score.

### Version 1 Status and Future Plans (43:40-44:02)

This represents the current state of version 1. Version 2 will perform the same function but with a better architecture, REST API endpoints, and smaller, more modular subsystems.

### Live Update and File Synchronization (44:05-44:12)

A question is asked about whether the system updates live when a document is changed. The speaker confirms that it does.


### Live Update Mechanism for File Synchronization (44:23-45:21)

The speaker explains the mechanism used for live updates and file synchronization in the RAG system.

*   A script file tracks file changes, specifying which changes to monitor.
*   `.NET` objects are used for this purpose, specifically a `FileSystemWatcher`.

```csharp
// Example using FileSystemWatcher to monitor file changes
using System;
using System.IO;

public class FileSystemWatcherExample
{
    public static void Main(string[] args)
    {
        // Define the path to watch
        string path = @"C:\Your\Directory\To\Watch";

        // Create a new FileSystemWatcher
        FileSystemWatcher watcher = new FileSystemWatcher(path);

        // Set the filters to watch for
        watcher.NotifyFilter = NotifyFilters.Attributes
                             | NotifyFilters.CreationTime
                             | NotifyFilters.DirectoryName
                             | NotifyFilters.FileName
                             | NotifyFilters.LastAccess
                             | NotifyFilters.LastWrite
                             | NotifyFilters.Security
                             | NotifyFilters.Size;

        watcher.Changed += OnChanged;
        watcher.Created += OnCreated;
        watcher.Deleted += OnDeleted;
        watcher.Renamed += OnRenamed;
        watcher.Error += OnError;

        // Only watch text files
        watcher.Filter = "*.txt";
        watcher.IncludeSubdirectories = true;
        watcher.EnableRaisingEvents = true;

        Console.WriteLine("Press enter to exit.");
        Console.ReadLine();
    }

    private static void OnChanged(object sender, FileSystemEventArgs e)
    {
        Console.WriteLine($"Changed: {e.FullPath}");
        // Add your logic here to handle file changes, e.g., re-sync the vector database
    }

    private static void OnCreated(object sender, FileSystemEventArgs e)
    {
        Console.WriteLine($"Created: {e.FullPath}");
        // Add your logic here to handle file creation
    }

    private static void OnDeleted(object sender, FileSystemEventArgs e)
    {
        Console.WriteLine($"Deleted: {e.FullPath}");
        // Add your logic here to handle file deletion
    }

    private static void OnRenamed(object sender, RenamedEventArgs e)
    {
        Console.WriteLine($"Renamed:");
        Console.WriteLine($"    Old: {e.OldFullPath}");
        Console.WriteLine($"    New: {e.FullPath}");
        // Add your logic here to handle file renaming
    }

    private static void OnError(object sender, ErrorEventArgs e) =>
        PrintException(e.GetException());

    private static void PrintException(Exception ex)
    {
        if (ex != null)
        {
            Console.WriteLine($"Message: {ex.Message}");
            Console.WriteLine("Stacktrace:");
            Console.WriteLine(ex.StackTrace);
            Console.WriteLine("Inner Exception:");
            PrintException(ex.InnerException);
        }
    }
}
```

*   The `FileSystemWatcher` monitors files for changes or deletions, eliminating the need for continuous scanning.
*   The system registers for different file system events.
*   Based on these events, the vector database is synchronized.

### Issue with Live Update Demo (45:21-45:31)

The speaker notes that the live update mechanism is not working on the demonstration laptop and needs further investigation to resolve a small bug in the code.

### Introduction to a New Tool: Common Palette (45:31-45:55)

The speaker transitions to showcasing a new tool called the **Common Palette**, presented as a replacement for Power Rename (PowerToys).

### Common Palette Features (45:55-47:32)

The **Common Palette** has several new features:

*   **App Search**: Allows searching through all the applications on the computer. Typing filters the results.
*   **Command Execution**: Any command can be executed directly from the palette, with customizable keyboard shortcuts.
*   **File Search**: Enables fast file searching on the computer.
*   **Website Bookmarks**: Allows adding bookmarks to favorite websites, accessible via the keyboard. The speaker humorously realizes they mistyped "blog" as "block."
*   **Window Switching**: Facilitates switching between open windows, filtering by text. The speaker notes this is helpful when many windows are open.

### Customizable Keyboard Shortcuts and User Experience (47:32-48:27)

*   Users can install extensions to extend the functionality of the palette (e.g., for Git or Obsidian).
*   Predefined actions or searches can be set up, triggered by specific keys (e.g., pressing "E" could bring up frequently used options).
*   The palette remembers the last chosen item.
*   The palette is designed for keyboard-centric use, leveraging shortcuts for efficiency.

### Web Search and Closing Remarks (48:27-48:49)

*   Web searches can be initiated from the palette using a shortcut (Alt+Enter).
*   The speaker concludes the demonstration and thanks the audience.
